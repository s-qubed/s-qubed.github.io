<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>How Confident are Video Models? Empowering Video Models to Express their Uncertainty</title>

    <!--  =====  FONTS & ICONS  =====  -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    <link rel="icon" href="./static/icon.png" />

    <!--  =====  CSS  =====  -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css" />

    <style>
        /* --- GLOBAL --- */
        body {
            background: #fff;
            font-family: "Noto Sans", sans-serif;
            font-size: 16px;
            line-height: 1.5;
            color: #333;
        }

        section {
            padding: 2.5rem 0;
        }

        /* --- SECTION COLORS --- */
        .section-gray {
            background: #f7f7f7;
        }

        /* --- TYPOGRAPHY & LINKS --- */
        .task-title {
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .publication-authors {
            margin-bottom: 1rem;
        }

        /* space below authors */
        .publication-authors a {
            color: #3273dc;
            text-decoration: none;
            white-space: nowrap;
        }

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO & SPACING TWEAKS --- */
        .publication-title {
            margin-top: 0.0rem;
            padding-top: 0.0rem;
        }

        .hero {
            padding-top: 0.75rem;
            padding-bottom: 0.5rem;
        }

        /* tighter gap above overview */
        .hero-body {
            padding: 1.5rem;
        }

        #overview.section {
            padding-top: 0.75rem;
        }

        /* tighter gap below hero */
        .publication-links {
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        /* gap between authors/icons & icons/logo */
        figure.lab-logo {
            margin-top: 0.75rem;
        }

        /* gap between icons and Princeton logo */
        /* #sim-robot.section{padding-bottom:0.1rem;} gap above simulation section */
        #bibtex.section- {
            padding-top: 0rem;
        }

        /* gap above BibTeX section */

        /* --- SLICK ARROWS --- */
        .slick-prev:before,
        .slick-next:before {
            color: #3273dc;
            font-size: 32px;
        }

        /* --- THUMBNAILS --- */
        .video-thumb {
            cursor: pointer;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin: 0 8px;
        }

        .video-thumb video {
            width: 100%;
            height: auto;
            display: block;
        }

        /* --- STAND‑ALONE VIDEOS --- */
        .overview-video,
        .sim-video {
            width: 100%;
            height: auto;
            border-radius: 0;
            box-shadow: none;
            pointer-events: none;
        }

        /* --- LAYOUT HELPERS --- */
        .task-block {
            margin-bottom: 3rem;
        }

        .task-carousel,
        .task-carousel-exp {
            margin-top: 1rem;
        }

        /* --- CONTENT WIDTH CONSISTENCY --- */
        .content-container {
            max-width: 960px;
            margin: 0 auto;
        }

        /* --- PDF EMBED --- */
        .pdf-container {
            margin-top: 1.5rem;
        }

        .pdf-container object {
            width: 100%;
            height: 600px;
            border: none;
        }

        /* --- REAL EXP IMG --- */
        .real-exp-img {
            width: 100%;
            height: auto;
            max-width: 100%;
        }

        /* --- LINK COLOR (lighter blue, closer to default hyperlinks) --- */

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO ↔ OVERVIEW GAP (shrink) --- */
        .hero {
            padding-bottom: 0rem;
        }

        /* was 0.5rem */
        #overview.section {
            padding-top: 0rem;
            padding-bottom: 0rem;
        }

        /* was 0.75rem */

        /* --- REAL-ROBOT ↔ SIMULATION GAP (shrink) --- */
        #real-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */
        #real-robot.section {
            padding-bottom: 2.5rem;
        }

        #sim-to-real-1 {
            margin-bottom: 0;
        }

        /* default Bulma ≈2.5rem */
        #sim-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */

        /* --- SIMULATION ↔ BIBTEX GAP (shrink) --- */
        #BibTeX.section {
            padding-top: 0.1rem;
        }

        /* tighten above BibTeX */
    </style>

    <!--  =====  Latex  =====  -->
    <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
</head>

<body>

    <!-- ===== HERO with title & authors ===== -->
    <section class="hero section">
        <div class="hero-body">
            <div class="container is-max-widescreen has-text-centered">
                <h1 class="title is-2 publication-title">
                    <div style="display: flex; align-items: center; justify-content: center;">
                        <div style="flex: 0 0 18%; text-align: center;">
                            <img src="static/icon.gif" alt="Icon" style="height: 3.5em; max-width: 100%;">
                        </div>
                        <div style="flex: 0 0 82%; text-align: left;">
                            How Confident are Video Models?  <br /> <span style="font-size: xx-large;"> Empowering Video Models to Express their Uncertainty </span>
                        </div>
                    </div>
                </h1>

                <!-- ===== AUTHORS (three rows, no underscores) ===== -->

                <div class="is-size-5 publication-authors">
                    <div>   
                        <span class="author-block"><a href="https://may0mei.github.io/">Zhiting&nbsp;Mei*</a></span>,
                        <span class="author-block"><a href="#">Ola&nbsp;Shorinwa*</a></span>,
                        <span class="author-block"><a
                                href="https://irom-lab.princeton.edu/majumdar/">Anirudha&nbsp;Majumdar</a></span>
                    </div>
                </div>
                <div>
                    <sup>&#42;</sup>Equal Contribution.
                </div>

                <!-- ===== RESOURCE ICONS ===== --> <!-- TODO -->
                <div class="publication-links">
                    <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (Coming Soon!)</span>
                    </a> 
                    <a href="#" class="external-link button is-normal is-rounded is-dark"
                        target="_blank" rel="noopener">
                        <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv (Coming Soon!)</span>
                    </a>
                    <a href="#"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="fab fa-youtube"></i></span><span>Video (Coming Soon!)</span>
                    </a>
                    <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fab fa-github"></i></span><span>Code (Coming Soon!)</span>
                    </a>
                </div>

                <!-- ===== LAB LOGO ===== -->

                <figure class="image is-inline-block lab-logo">
                    <img src="static/irom_princeton.png" alt="IROM Lab logo" style="max-width:500px;">
                </figure>

            </div>
        </div>
    </section>

    <!-- ===== OVERVIEW ===== -->
    <section id="overview" class="section">
        <div class="container is-max-desktop content-container has-text-centered">
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/banner.jpg">
                <source src="static/videos/overviews/banner.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <p style="margin-top:1rem;">We introduce
                <strong>Semantically-Quantifying&nbsp;Uncertainty&nbsp;with&nbsp;Bayesin&nbsp;Decomposition (S-QUBED)</strong>, a method to
                quantify the uncertainty for generative video models.
            </p>
        </div>
    </section>

    <!-- ===== ABSTRACT ===== -->
    <section id="abstract" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <p>
                Generative video models demonstrate impressive text-to-video capabilities,
                spurring widespread adoption in many real-world applications. However, like
                large language models (LLMs), video generation models tend to hallucinate, pro-
                ducing plausible videos even when they are factually wrong. Although uncertainty
                quantification (UQ) of LLMs has been extensively studied in prior work, no UQ
                method for video models exists, raising critical safety concerns. To our knowl-
                edge, this paper represents the first work towards quantifying the uncertainty of
                video models. We present a framework for uncertainty quantification of generative
                video models, consisting of: (i) a metric for evaluating the calibration of video
                models based on robust rank correlation estimation with no stringent modeling
                assumptions; (ii) a black-box UQ method for video models (termed S-QUBED),
                which leverages latent modeling to rigorously decompose predictive uncertainty
                into its aleatoric and epistemic components; and (iii) a UQ dataset to facilitate
                benchmarking calibration in video models, which will be released after the review
                process. By conditioning the generation task in the latent space, we disentangle
                uncertainty arising due to vague task specifications from that arising from lack
                of knowledge. Through extensive experiments on benchmark video datasets, we
                demonstrate that S-QUBED computes calibrated total uncertainty estimates that are
                negatively correlated with the task accuracy and effectively computes the aleatoric
                and epistemic constituents.
            </p>
            <!-- <br>
      <video id="summary-video" class="shadow" controls preload="metadata" width="100%" poster="static/thumbnails/talk_video.jpg">
        <source src="static/videos/talk_video.mp4" type="video/mp4" />
        Your browser does not support the video tag.
      </video> -->
        </div>
    </section>

    <!-- ===== Architecture ===== -->
    <section id="architecture" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">S-QUBED Method</h2>
            <video class="overview-video" autoplay loop muted playsinline poster="static/thumbnails/architecture.jpg">
                <source src="static/videos/overviews/architecture.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
            Given a text prompt <img src="static/images/l.svg" alt="ℓ" style="display: inline; height: 1em; vertical-align: baseline;">, our goal is to quantify the uncertainty
            of the video generation model. We first generate n latent prompts consistent with <img src="static/images/l.svg" alt="ℓ" style="display: inline; height: 1em; vertical-align: baseline;"> in line with the
            prompt refinement used by video models, modeling the aleatoric uncertainty as the entropy of the
            distribution over latent prompts. Then, for each latent prompt, we generate m videos, modeling the
            epistemic uncertainty as the conditional entropy of the distribution over generated videos. Finally,
            aggregating the two types of uncertainties yields the total predictive uncertainty.
            </p>
        </div>
        
        <!-- ===== Aleatoric ===== -->
        <div class="container is-max-desktop content-container">
            <h3 class="title is-4 has-text-centered" style="margin-top: 3rem;">Aleatoric Uncertainty</h3>
                <p>
                    Aleatoric uncertainty encompasses irreducible randomness from the vagueness (lack of sufficient
                    specificity) of the conditioning inputs, e.g., “generate a video of a cat doing something.” In video
                    generation, vagueness in the input prompt increases the randomnes of the generation of latent prompts.
                </p>
                <div style="display: flex; align-items: center; justify-content: center; margin: 0 2rem; margin-top: 1rem">
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/cat_doing_something_0.jpg" preload="metadata">
                            <source src="static/videos/overviews/cat_doing_something_0.mp4" type="video/mp4" />
                        </video>
                    </div>
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/cat_doing_something_1.jpg" preload="metadata">
                            <source src="static/videos/overviews/cat_doing_something_1.mp4" type="video/mp4" />
                        </video>
                    </div>
                </div>
                    <p style="text-align: left;"><strong>High aleatoric unc:</strong> "Generate a video of a cat doing something."</p>
                <div style="display: flex; align-items: center; justify-content: center; margin: 0 2rem; margin-top: 1rem">
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/cat_napping_0.jpg" preload="metadata">
                            <source src="static/videos/overviews/cat_napping_0.mp4" type="video/mp4" />
                        </video>
                    </div>
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/cat_napping_1.jpg" preload="metadata">
                            <source src="static/videos/overviews/cat_napping_1.mp4" type="video/mp4" />
                        </video>
                    </div>
                </div>
                <p style="text-align: left;"><strong>Low aleatoric unc:</strong> "A close-up shot of a tabby cat napping on a couch with lots of sunlight coming in through the windows."</p>
            </div>

        <!-- ===== Epistemic ===== -->
        <div class="container is-max-desktop content-container">
            <h3 class="title is-4 has-text-centered" style="margin-top: 3rem;">Epistemic Uncertainty</h3>

                <p>
                    Epistemic uncertainty represents the measure of doubt associated with a lack of knowledge, which
                    generally results from insufficient training data. 
                    As a result, epistemic uncertainty isreducible by providing additional training data to the model.
                    For example, consider a video model trained entirely on internet videos of cats and dogs performing
                    different activities, e.g., running, eating, jumping, meowing/barking. Now, when asked to generate a
                    video of “a lion roaring in the wild”, the video model might generate different videos across different
                    runs, with some showing a large cat meowing in a park with significant tree canopy, others showing a
                    cat making barking-like sounds in a forest, etc. Although the generated videos are all conditioned
                    on semantically-consistent latent variables, the generated videos might be semantically-inconsistent,
                    since the video model has not been trained on videos of lions.
                </p>
                <div style="display: flex; align-items: center; justify-content: center; margin: 0 2rem; margin-top: 1rem">
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/violet_0.jpg" preload="metadata">
                            <source src="static/videos/overviews/violet_0.mp4" type="video/mp4" />
                        </video>
                    </div>
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/violet_1.jpg" preload="metadata">
                            <source src="static/videos/overviews/violet_1.mp4" type="video/mp4" />
                        </video>
                    </div>
                </div>
                    <p style="text-align: left;"><strong>High epistemic unc:</strong> "Generate a video of Violet Evergarden walking with an umbrella."</p>
                <div style="display: flex; align-items: center; justify-content: center; margin: 0 2rem; margin-top: 1rem">
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/luffy_0/.jpg" preload="metadata">
                            <source src="static/videos/overviews/luffy_0.mp4" type="video/mp4" />
                        </video>
                    </div>
                    <div style="flex: 0 0 40%; text-align: center; margin: 0 1rem;">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/overviews/luffy_1.jpg" preload="metadata">
                            <source src="static/videos/overviews/luffy_1.mp4" type="video/mp4" />
                        </video>
                    </div>
                </div>
                <p style="text-align: left;"><strong>Low epistemic unc:</strong> "Generate a video of Luffy walking with an umbrella."</p>
            </div>
        </div>

    </section>



    <!-- ===== TODO ===== -->

    <!-- ===== Experiments ===== -->
    <section id="experiment-results" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Experiments</h2>
            <p class="has-text-justified">

            </p>
            <br>

            <!-- ===== Q1: Metric ===== -->
            <div class="task-block" id="q1">
                <h3 class="title is-4 task-title">How do we evaluate uncertainty calibration of video models?</h3>
                <!-- Result plot-->
                <img src="./static/images/rank_correlation.png" class="real-exp-img" alt="Calibration Plot." />

                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                    Calibration Metrics for Video Models. Top: We examine the statistical significance of
                    the Kendall rank correlation between uncertainty and widely-used perceptual metrics. We find that
                    the CLIP cosine similarity score provides the most significant correlation. Bottom: With the CLIP
                    accuracy metric, we observe that low human-annotated uncertainty corresponds to smaller variance
                    in the generated videos and greater accuracy with respect to the ground-truth video. As uncertainty
                    increases, video prediction accuracy decreases.
                </p>


                <h5 class="title is-6 task-title">Ground-Truth Videos</h5>
                <div class="task-carousel">
                    <!-- Six videos with poster extracted via Python script --> 
                    <!--TODO: fix video caption style-->
                    <!--TODO: add more videos-->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/moon/0001404_00000.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/moon/0001404_00000.mp4" type="video/mp4" /></video>
                        <p>"A close up of a moon with holes in it."</p>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/blender/0000702_00002.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/blender/0000702_00002.mp4" type="video/mp4" /></video>
                        <p>"A blender filled with sliced oranges on a counter."</p>
                    </div>
                    <!-- <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/powder/0000710_00000.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/powder/0000710_00000.mp4" type="video/mp4" /></video>
                        <p>"There is a white powdery substance in a bowl with the word "flour" written on it."</p>
                    </div> -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/game/0001302_00000.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/game/0001302_00000.mp4" type="video/mp4" /></video>
                        <p>"A video game screen showing a list of items."</p>
                    </div>
                </div>
                <br>

                <h5 class="title is-6 task-title">Generated Videos</h5>
                <div class="task-carousel">
                    <!-- Six videos with poster extracted via Python script -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/moon/0001404_00000/latent_2/videos/gen_video_226.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/moon/0001404_00000/latent_2/videos/gen_video_226.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/blender/0000702_00002latent_0/videos/gen_video_100.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/blender/0000702_00002/latent_0/videos/gen_video_100.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/game/0001302_00000/latent_0/videos/gen_video_201.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/game/0001302_00000/latent_0/videos/gen_video_201.mp4" type="video/mp4" /></video>
                    </div>
                </div>
                <div class="task-carousel">
                    <!-- Six videos with poster extracted via Python script -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/moon/0001404_00000/latent_7/videos/gen_video_274.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/moon/0001404_00000/latent_7/videos/gen_video_274.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/blender/0000702_00002latent_1/videos/gen_video_110.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/blender/0000702_00002/latent_1/videos/gen_video_110.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/game/0001302_00000/latent_1/videos/gen_video_210.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/game/0001302_00000/latent_1/videos/gen_video_210.mp4" type="video/mp4" /></video>
                    </div>
                </div>

                <div class="task-carousel">
                <!-- Six videos with poster extracted via Python script -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/moon/0001404_00000/latent_9/videos/gen_video_290.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/moon/0001404_00000/latent_9/videos/gen_video_290.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/blender/0000702_00002latent_9/videos/gen_video_195.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/blender/0000702_00002/latent_9/videos/gen_video_195.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/metric/game/0001302_00000/latent_2/videos/gen_video_222.jpg" preload="metadata">
                        <source src="static/videos/experiments/metric/game/0001302_00000/latent_2/videos/gen_video_222.mp4" type="video/mp4" /></video>
                    </div>
                </div>
                <br>
            </div>


            <!-- ===== Q2: Total Unc ===== -->
            <div class="task-block" id="q2">
                <h3 class="title is-4 task-title">Are the total predictive uncertainty estimates computed by S-QUBED calibrated?</h3>
                <!-- Result plot-->
                <img src="./static/images/total_pred_unc.png" class="real-exp-img" alt="Calibration Plot." />

                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                    Total Predictive Uncertainty for Video Models. We assess the calibration of the
                    total predictive uncertainty computed by S-QUBED. Top: correlation between video prediction
                    accuracy and total uncertainty for Panda-70M and VidGen-1M . We observe a statistically significant
                    correlation between accuracy and uncertainty for both datasets, signified by the small p-values.
                    Bottom: visualization of two samples from Panda-70M.
                </p>

                <h5 class="title is-6 task-title">Ground-Truth Videos</h5>
                <div class="task-carousel-exp">
                    <div class="video-thumb">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/lab/0001316_00001.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/lab/0001316_00001.mp4" type="video/mp4" /></video>
                        <div style="display: flex; justify-content: center; align-items: center; margin-top: 0.5rem;">
                            <img src="static/images/a_icon.png" alt="A" class="real-exp-img" style="width: 3rem;" />
                        </div>
                    </div>
                    <div class="video-thumb">
                        <video class="thumb-video" autoplay loop muted playsinline
                            poster="static/thumbnails/sexperiments/decompose/cooking/0000134_00001.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/cooking/0000134_00001.mp4" type="video/mp4" /></video>
                        <div style="display: flex; justify-content: center; align-items: center; margin-top: 0.5rem;">
                            <img src="static/images/b_icon.png" alt="B" class="real-exp-img" style="width: 2.5rem;" />
                        </div>    
                    </div>
                </div>
                <br>
                
                <h5 class="title is-6 task-title">Generated Videos</h5>
                <div class="task-carousel-exp">
                    <!-- Six videos with poster extracted via Python script -->
                    <!-- TODO: add more generated videos -->
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/decompose/lab_gen/gen_video_200.jpg" preload="metadata">
                        <source src="static/videos/experiments/decompose/lab_gen/gen_video_200.mp4" type="video/mp4" /></video>
                    <p>"A man is sitting… laboratory and talking to the camera…blue shirt… a jar of peanuts…"</p>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" autoplay loop muted playsinline
                        poster="static/thumbnails/experiments/decompose/cooking_gen/gen_video_203.jpg" preload="metadata">
                        <source src="static/videos/experiments/decompose/cooking_gen/gen_video_203.mp4" type="video/mp4" /></video>
                    <p>"A woman is cooking food in a white pot on a gas stove."</p>
                    </div>
                </div>
            </div>

            <!-- ===== Q3: Decomposition ===== -->
            <div class="task-block" id="q3">
                <h3 class="title is-4 task-title">Can S-QUBED effectively estimate both aleatoric and epistemic uncertainty?</h3>
                <!-- Result plot-->
                <img src="./static/images/decomposed_pred_unc.png" class="real-exp-img" alt="Calibration Plot." />

                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                    Disentangling Aleatoric and Epistemic Uncertainty for Video Models. We demonstrate
                    the calibration of the aleatoric uncertainty estimates of S-QUBED in tasks with no epistemic uncertainty, 
                    showing statistically significant negative correlation. We do the same for epistemic uncertainty.
                </p>
                
                <h5 class="title is-6 task-title">Ground-Truth Videos</h5>
                
                <div class="task-carousel">
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/cat/0001620_00001.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/cat/0001620_00001.mp4" type="video/mp4" /></video>
                        <p><strong>Low aleatoric:</strong> "A black cat with blue eyes is sitting on a blue carpet looking at the camera."</p>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/school/0000403_00002.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/school/0000403_00002.mp4" type="video/mp4" /></video>
                        <p><strong>High aleatoric:</strong> "A display of pictures and information about a school."</p>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/beard/0001919_00002.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/beard/0001919_00002.mp4" type="video/mp4" /></video>
                        <p><strong>Low epistemic:</strong>"A man with a beard is talking into a microphone while sitting at a desk."</p>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/logo/0001804_00000.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/logo/0001804_00000.mp4" type="video/mp4" />
                        </video>
                        <p><strong>High epistemic:</strong> "The logo for behind the gloves is on a black background."</p>
                    </div>
                </div>
                <br>

                <h5 class="title is-6 task-title">Generated Videos</h5>
                <div class="task-carousel">
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/cat_gen/gen_video_203.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/cat_gen/gen_video_203.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/school_gen/gen_video_223.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/school_gen/gen_video_223.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/beard_gen/gen_video_113.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/beard_gen/gen_video_113.mp4" type="video/mp4" /></video>
                    </div>
                    <div class="video-thumb"><video class="thumb-video" controls onloadstart="this.playbackRate = 1.0;"
                            autoplay loop muted playsinline
                            poster="static/thumbnails/experiments/decompose/ogo_gen/gen_video_21.jpg" preload="metadata">
                            <source src="static/videos/experiments/decompose/logo_gen/gen_video_21.mp4" type="video/mp4" />
                        </video>
                    </div>
                </div>

            </div>
        </div>
    </section>



    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>

        </code></pre>
        </div>
    </section>


    <br>
    <center class="is-size-10">
        The website design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>

    <!-- ===== SCRIPTS ===== -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
    <script>
        $(function () {
            // Init carousels (only those still using .task-carousel wrappers)
            $('.task-carousel').slick({
                slidesToShow: 4,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 3 } },
                    { breakpoint: 768, settings: { slidesToShow: 2 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

            $('.task-carousel-exp').slick({
                slidesToShow: 3,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 1 } },
                    { breakpoint: 768, settings: { slidesToShow: 1 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });
            $('.task-carousel-exp').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

        });
    </script>
</body>

</html>